{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import arabic_reshaper\n",
    "from bidi import algorithm \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Datasetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# read by default 1st sheet of an excel file\n",
    "data1 = pd.read_excel('final-data.xlsx')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of null values in each column\n",
    "null_counts = data1.isnull().sum()\n",
    "\n",
    "# Print the null counts for each column\n",
    "print(null_counts)\n",
    "\n",
    "# Convert the null_counts Series to a DataFrame\n",
    "null_counts_df = null_counts.to_frame('Null_Count')\n",
    "\n",
    "# Save the results to an Excel file\n",
    "null_counts_df.to_excel('null_counts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = data1.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Print the categorical columns\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_cols = data1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Print the categorical columns\n",
    "print(\"numerical columns:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1\n",
    "df.columns = [arabic_reshaper.reshape(column) for column in data1.columns]\n",
    "# Plotting value counts and distribution for each column separately\n",
    "for col in df.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Value Counts\n",
    "   # plt.subplot(1, 2, 1)\n",
    "    #df[col].value_counts().plot(kind='bar', color='skyblue')\n",
    "    #plt.title(f'Value Counts for {col}')\n",
    "    #plt.xlabel('Unique Values')\n",
    "    #plt.ylabel('Count')\n",
    "\n",
    "    # Distribution\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "        plt.title(f'توزیع {arabic_reshaper.reshape(col)}')\n",
    "    else:\n",
    "        sns.histplot(df[col], color='skyblue', bins=10)\n",
    "        plt.title(f'توزیع {arabic_reshaper.reshape(col)}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in categorical variables\n",
    "for catcol in categorical_cols:\n",
    "    #print(catcol)\n",
    "    mode_value = data1[catcol].mode()[0]\n",
    "    data1[catcol].fillna(mode_value, inplace=True)\n",
    "# Calculate the mean of the numerical column with missing values\n",
    "for numcol in numerical_cols:\n",
    "    #print(numcol)\n",
    "    mode_value = data1[numcol].mode()[0]\n",
    "    #print(mode_value)\n",
    "    data1[numcol].fillna(mode_value, inplace=True)\n",
    "# Print the null counts for each column\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Count the number of occurrences for each class\n",
    "class_counts = data1['خروج'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Class Distribution')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value decsribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mearge features and target and plot correlation\n",
    "\n",
    "data = pd.concat([features, pd.DataFrame(target, columns=['خروج'])], axis=1)\n",
    "#change column names to persian\n",
    "data.columns = [arabic_reshaper.reshape(column) for column in data.columns]\n",
    "data.columns = [algorithm.get_display(column) for column in data.columns]\n",
    "corr = data.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.1f')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (if any)\n",
    "encoder = LabelEncoder()\n",
    "for catcol in categorical_cols:\n",
    "   data1[catcol] = encoder.fit_transform(data1[catcol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Split - Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "features = data1.drop('خروج', axis=1)\n",
    "target = data1['خروج']\n",
    "df_columns = features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# تعیین مدل استخراج ویژگی\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# انطباق مدل با داده‌های آموزشی\n",
    "clf.fit(features, target)\n",
    "\n",
    "# محاسبه اهمیت ویژگی ها\n",
    "clf_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "clf_feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': clf_importances})\n",
    "\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "clf_feature_importances = clf_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(clf_feature_importances)\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "clf_feature_importances.to_excel('clf_feature_importances.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the random forest regressor model\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "rf_model.fit(features, target)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "rf_feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': rf_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "rf_feature_importances = rf_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(rf_feature_importances)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "rf_feature_importances.to_excel('rf_feature_importances.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#حذف ویژگی بازگشتی\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Create the random forest classifier model\n",
    "rfc_model = RandomForestClassifier()\n",
    "\n",
    "# Create the RFE selector with the random forest classifier\n",
    "rfe_selector = RFE(estimator=rfc_model, n_features_to_select=11, step=1)\n",
    "\n",
    "# Fit the RFE selector to the data\n",
    "rfe_selector.fit(features, target)\n",
    "\n",
    "# Get the rankings of the features\n",
    "feature_rankings = rfe_selector.ranking_\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = features.columns[rfe_selector.support_]\n",
    "\n",
    "# Print the selected features and their rankings\n",
    "for feature, ranking in zip(selected_features, feature_rankings):\n",
    "    print(f\"{feature}: {ranking}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#درختان اضافی\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Create the Extra Trees classifier model\n",
    "et_model = ExtraTreesClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "et_model.fit(features, target)\n",
    "\n",
    "# Get feature importances\n",
    "et_feature_importances = et_model.feature_importances_\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "et_feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': et_feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "et_feature_importances = et_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(et_feature_importances)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "et_feature_importances.to_excel('et_feature_importances.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Perform chi-square test for each feature\n",
    "chi2_feature_importances = []\n",
    "for feature in features.columns:\n",
    "    contingency_table = pd.crosstab(features[feature], target)\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    chi2_feature_importances.append(( chi2))\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "chi2_feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': chi2_feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "chi2_feature_importances = chi2_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(chi2_feature_importances)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "chi2_feature_importances.to_excel('chi2_feature_importances.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "# Create and fit the Lasso regression model\n",
    "lasso = Lasso(alpha=0.1)  # alpha is the regularization strength\n",
    "lasso.fit(features, target)\n",
    "\n",
    "# Get the feature importance scores\n",
    "l_feature_importances = np.abs(lasso.coef_)\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "l_feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': l_feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "l_feature_importances = l_feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(l_feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE on Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (optional),add stratify\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical columns\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of ROWs before SMOTE')\n",
    "print('y_train:\\n',y_train.value_counts())\n",
    "print('y_test:\\n',y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy=0.033)\n",
    "X_train_s, y_train_s = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of ROWs after SMOTE')\n",
    "print('y_train:\\n',y_train_s.value_counts())\n",
    "print('y_train:\\n',y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"LGBMClassifier\")\n",
    "# Perform k-fold cross-validation and generate classification report for each fold\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(features, target), 1):\n",
    "    X_train, X_test = features.loc[train_idx], features.loc[test_idx]\n",
    "    y_train, y_test = target.loc[train_idx], target.loc[test_idx]\n",
    "    \n",
    "    sm = SMOTE(sampling_strategy=0.062)\n",
    "    X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "    rf_clf = lgb.LGBMClassifier(random_state=42)\n",
    "    rf_clf.fit(X_train_s, y_train_s)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(f'Classification Report for Fold {fold_idx}:')\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"XGBClassifier\")\n",
    "# Perform k-fold cross-validation and generate classification report for each fold\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(features, target), 1):\n",
    "    X_train, X_test = features.loc[train_idx], features.loc[test_idx]\n",
    "    y_train, y_test = target.loc[train_idx], target.loc[test_idx]\n",
    "    \n",
    "    sm = SMOTE(sampling_strategy=0.062)\n",
    "    X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "    rf_clf = XGBClassifier(random_state=42)\n",
    "    rf_clf.fit(X_train_s, y_train_s)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(f'Classification Report for Fold {fold_idx}:')\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"RandomForestClassifier\")\n",
    "\n",
    "# Perform k-fold cross-validation and generate classification report for each fold\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(features, target), 1):\n",
    "    X_train, X_test = features.loc[train_idx], features.loc[test_idx]\n",
    "    y_train, y_test = target.loc[train_idx], target.loc[test_idx]\n",
    "    \n",
    "    sm = SMOTE(sampling_strategy=0.062)\n",
    "    X_train_s, y_train_s = sm.fit_resample(X_train, y_train)\n",
    "    rf_clf = RandomForestClassifier(random_state=42)\n",
    "    rf_clf.fit(X_train_s, y_train_s)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(f'Classification Report for Fold {fold_idx}:')\n",
    "    print(class_report)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "991960316caac4da9ee563e2d61b1be3a53b1cf0fd7c550f76474241a227f690"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
